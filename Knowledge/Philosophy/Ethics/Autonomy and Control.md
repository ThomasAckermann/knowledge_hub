#Robotics #Ethics #Philosophy

Ethical Issue: Who is morally responsible for [[Robot]] actions?
What is implied by moral responsibility:
## Moral responsibility as Guidance Control

Reason-Responsive Mechanism:
- A acts according to moral reasons, such as respect for autonomy, prevention of harm, caring for well-begin of others, accountability and fairness, consideration off law and social norms
- When A acts, he or she does so with an awareness of the reasons behind their decisions
Ownership Condition
- A must recognize it's moral reasons as his or her own
- If A's actions are the result of manipulation or external influence, guidance [[Control]] may not hold, as A may not genuinely own those actions

## Unpredictability & Black Box Decision-Making

- Many AI models operate as black boxes, making decisions that even their creators cannot fully explain (Responsibility Gaps)
- If an AI system makes an unethical or biased decision, it's unclear who should be held responsible
- If an AI system makes a harmful decision, should responsibility fall on the developer, manufacturer, user or regulator?
- Sine AI systems operate with a degree of autonomy and unpredictability, traditional accountability models like guidance [[Control]] struggle to determine who is responsible when something goes wrong


## Meaningful Human Control

Tracking Condition: The autonomous system can respond to relevant moral reasons, as well as the pertinent facts of the environment in which it operates
Tracing Condition: The outcomes of the system's operations should be tracable to at least one human involved in the design or operation chain